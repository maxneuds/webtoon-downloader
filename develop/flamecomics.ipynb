{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_flamecomics_chapters(url):\n",
    "    \"\"\"\n",
    "    Scrapes chapter links and their details from a given flamecomics.xyz series URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the series on flamecomics.xyz.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing chapter details.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Fetch the webpage content\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP responses\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Find all chapter elements\n",
    "        chapters = []\n",
    "        chapter_elements = soup.find_all('a', class_='ChapterCard_chapterWrapper__j8pBx')\n",
    "\n",
    "        for chapter in chapter_elements:\n",
    "            chapter_data = {\n",
    "                'link': chapter['href'],  # Extract the chapter link\n",
    "                'title': chapter.find('p', class_='mantine-Text-root').text.strip(),  # Extract the chapter title\n",
    "                'date': chapter.find_all('p', class_='mantine-Text-root')[1].text.strip(),  # Extract the date\n",
    "                'reactions': [\n",
    "                    img['alt'] for img in chapter.find_all('img', class_='ReactionBarMini_reactionIcon__rkqnd')\n",
    "                ]  # Extract reaction icons\n",
    "            }\n",
    "            chapters.append(chapter_data)\n",
    "\n",
    "        return chapters\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching the URL: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "url = \"https://flamecomics.xyz/series/2\"\n",
    "chapters = scrape_flamecomics_chapters(url)\n",
    "for chapter in chapters:\n",
    "    print(chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: Solo Leveling - Ragnarok, Chapter 22.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 23.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 24.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 25.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 29.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 30.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 31.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 32.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 33.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 34.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 35.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 36.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 37.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 38.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 39.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 40.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 41.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 42.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 43.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 44.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 45.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 46.cbz\n",
      "Downloading: Solo Leveling - Ragnarok, Chapter 47.cbz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# url = \"https://flamecomics.xyz/series/2\"\n",
    "url = \"https://flamecomics.xyz/series/143\"\n",
    "\n",
    "response = requests.get(url)\n",
    "response.raise_for_status()  # Raise an error for bad HTTP responses\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Find the <script> tag with id=\"__NEXT_DATA__\"\n",
    "script_tag = soup.find('script', id='__NEXT_DATA__', type='application/json')\n",
    "if script_tag:\n",
    "    # Extract the JSON content and parse it into a Python dictionary\n",
    "    dat = json.loads(script_tag.string)['props']['pageProps']\n",
    "else:\n",
    "    print(\"No series object (__NEXT_DATA__) found.\")\n",
    "\n",
    "series_title = dat['series']['title']\n",
    "series_title = series_title.replace(\":\", \" -\")\n",
    "\n",
    "# Create a folder with the series name if it doesn't already exist\n",
    "dir_base = os.path.join(\"..\", \"data\")\n",
    "if not os.path.exists(dir_base):\n",
    "    os.makedirs(dir_base)\n",
    "# Create a subfolder for the series\n",
    "dir_series = os.path.join(dir_base, series_title)\n",
    "if not os.path.exists(dir_series):\n",
    "    os.makedirs(dir_series)\n",
    "\n",
    "chapters = dat['chapters']\n",
    "chapters = sorted(chapters, key=lambda x: float(x['chapter']))\n",
    "for chapter in chapters:\n",
    "    series_id = chapter['series_id']\n",
    "    chapter_title = chapter['title']\n",
    "    chapter_number = chapter['chapter']\n",
    "    chapter_number = chapter_number.split(\".\")[0] if chapter_number.endswith(\".0\") else chapter_number\n",
    "    chapter_token = chapter['token']\n",
    "    cbz_filename = f\"{series_title}, Chapter {chapter_number}.cbz\"\n",
    "    file_cbz = os.path.join(dir_series, cbz_filename)\n",
    "    if os.path.exists(file_cbz):\n",
    "        # print(f\"{cbz_filename} already exists, skipping download.\")\n",
    "        continue\n",
    "    # Check if the chapter has images\n",
    "    if not chapter['images']:\n",
    "        print(f\"No images found for chapter {chapter_number}. Skipping download.\")\n",
    "        continue\n",
    "    # Check if the chapter has a token\n",
    "    if not chapter_token:\n",
    "        print(f\"No token found for chapter {chapter_number}. Skipping download.\")\n",
    "        continue\n",
    "    # Check if the chapter has a series ID\n",
    "    if not series_id:\n",
    "        print(f\"No series ID found for chapter {chapter_number}. Skipping download.\")\n",
    "        continue\n",
    "    images = chapter['images']\n",
    "    imgs = []\n",
    "    images = dict(sorted(images.items(), key=lambda item: int(item[0])))\n",
    "    print(f\"Downloading: {cbz_filename}\")\n",
    "    for key in images:\n",
    "        image = images[key]\n",
    "        img_name = image['name']\n",
    "        img_name = img_name.replace(\" \", \"%20\")\n",
    "        img_type = image['type']\n",
    "        img_type = img_type[0] if isinstance(img_type, list) else img_type\n",
    "        url_image = f\"https://cdn.flamecomics.xyz/series/{series_id}/{chapter_token}/{img_name}\"\n",
    "        # Download the image\n",
    "        image_response = requests.get(url_image)\n",
    "        image_response.raise_for_status()  # Ensure the request was successful\n",
    "        # Load the image into memory\n",
    "        img = Image.open(BytesIO(image_response.content))\n",
    "        # Add image to im memory list\n",
    "        imgs.append([img, img_type])\n",
    "    # Save images as a CBZ file\n",
    "    with BytesIO() as cbz_buffer:\n",
    "        # Save all images into the buffer as a ZIP archive\n",
    "        with zipfile.ZipFile(cbz_buffer, 'w') as cbz:\n",
    "            for idx, img in enumerate(imgs):\n",
    "                img_filename = f\"{idx + 1:03}.jpg\"\n",
    "                with BytesIO() as img_buffer:\n",
    "                    if img[1] == 'image/jpeg':\n",
    "                        img[0].save(img_buffer, format='JPEG')\n",
    "                    elif img[1] == 'image/png':\n",
    "                        img[0] = img[0].convert(\"RGB\")\n",
    "                        img[0].save(img_buffer, format='JPEG')\n",
    "                    cbz.writestr(img_filename, img_buffer.getvalue())\n",
    "        # Write the buffer to a file\n",
    "        with open(file_cbz, 'wb') as cbz_file:\n",
    "            cbz_file.write(cbz_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIs\n",
    "https://flamecomics.xyz/api/series"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
